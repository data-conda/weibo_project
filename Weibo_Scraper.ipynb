{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e85c0bfc",
      "metadata": {
        "id": "e85c0bfc"
      },
      "source": [
        "# This notebook scrapes hashtags from main pages of brands in Weibo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f45c4d61",
      "metadata": {
        "id": "f45c4d61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9dd6fe8-da6a-453c-a802-4f006b5936f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting weibo-scraper\n",
            "  Downloading weibo_scraper-1.0.6-py2.py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from weibo-scraper) (2.25.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->weibo-scraper) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->weibo-scraper) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->weibo-scraper) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->weibo-scraper) (2.10)\n",
            "Installing collected packages: weibo-scraper\n",
            "Successfully installed weibo-scraper-1.0.6\n"
          ]
        }
      ],
      "source": [
        "#necessary installations\n",
        "!pip install weibo-scraper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "34fff967",
      "metadata": {
        "id": "34fff967"
      },
      "outputs": [],
      "source": [
        "from weibo_scraper import get_formatted_weibo_tweets_by_name\n",
        "from weibo_scraper import  get_weibo_tweets\n",
        "import re\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "009885ba",
      "metadata": {
        "id": "009885ba"
      },
      "outputs": [],
      "source": [
        "#dictionary with Chinese names of accounts\n",
        "data_dict_en = {\"BMW\":\"宝马中国\"}\n",
        "data_dict_cn = {\"宝马中国\":\"BMW\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ea9332dd",
      "metadata": {
        "id": "ea9332dd"
      },
      "outputs": [],
      "source": [
        "def post_scraper(brand_name: str) -> list:\n",
        "    \"\"\"\n",
        "    post_scraper collects metadata of posts from the main page of the brand in Weibo.  \n",
        "\n",
        "    :param brand_name: exact name of the brand in Weibo.\n",
        "    :return: list of posts in html text format\n",
        "    \"\"\"\n",
        "    result_iterator = get_formatted_weibo_tweets_by_name(name=brand_name, pages=None)\n",
        "    cnt = 0\n",
        "    posts = []\n",
        "    for user_meta in tqdm(result_iterator):\n",
        "        if user_meta is not None:\n",
        "            for tweetMeta in user_meta.cards_node:\n",
        "                posts.append(tweetMeta.mblog.text)\n",
        "                cnt = cnt + 1\n",
        "                if cnt>100:\n",
        "                  break\n",
        "            else:\n",
        "            # Continue if the inner loop wasn't broken.\n",
        "              continue\n",
        "            # Inner loop was broken, break the outer.\n",
        "            break\n",
        "    print(f'{data_dict_cn[brand_name]} has {cnt} number of posts')\n",
        "    return posts\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "2837d815",
      "metadata": {
        "id": "2837d815"
      },
      "outputs": [],
      "source": [
        "def hashtag_collector(posts: list) -> dict:\n",
        "    \"\"\"\n",
        "    hashtag_collector gets hashtags from posts and convert them into dictionary in decreasing order.  \n",
        "\n",
        "    :param posts: posts from the main page of the brand\n",
        "    :return: dictionary of hashtags grouped by each post in decreasing order\n",
        "    \"\"\"\n",
        "    filtered_post = []\n",
        "    for post in posts:\n",
        "        idx = [m.start() for m in re.finditer('#', post)]\n",
        "        i = 0\n",
        "        hashtags = []\n",
        "        if ((len(idx)%2==0) and (len(idx)>0)):\n",
        "            while i < len(idx):\n",
        "                hashtags.append(post[idx[i]+1: idx[i+1]])\n",
        "                i = i+2\n",
        "            filtered_post.append(hashtags)\n",
        "    dict_post = dict(list(enumerate(filtered_post)))\n",
        "    return dict_post"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "826cb0e4",
      "metadata": {
        "id": "826cb0e4"
      },
      "outputs": [],
      "source": [
        "def container_id_extractor(posts: list) -> list:\n",
        "    \"\"\"\n",
        "    container_id_extractor collects container_id of posts from the metadata text of posts.  \n",
        "\n",
        "    :param posts: posts extracted from Weibo\n",
        "    :return: list of container_ids of all posts\n",
        "    \"\"\" \n",
        "    container_list = []\n",
        "    for post in posts:\n",
        "        if 'containerid' in post:\n",
        "            temp_list = post.split('containerid=')[1:]\n",
        "            for text in temp_list:\n",
        "                container_id = text.partition('&')[0]\n",
        "                container_list.append(container_id)\n",
        "    return container_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "65c3d5b7",
      "metadata": {
        "id": "65c3d5b7"
      },
      "outputs": [],
      "source": [
        "def container_metadata_extractor(containers: list, brand: str):\n",
        "    \"\"\"\n",
        "    container_metadata_extractor collects metadata from each post based on container_id  \n",
        "\n",
        "    :param posts: posts extracted from Weibo\n",
        "    :return: list of container_ids of all posts\n",
        "    \"\"\" \n",
        "    brand_name = []\n",
        "    created_at = []\n",
        "    n_likes = []\n",
        "    n_comments = []\n",
        "    n_reposts = []\n",
        "    container_id = []\n",
        "    content = []\n",
        "    cnt = 0\n",
        "    for c_id in tqdm(containers):\n",
        "        for tweet in get_weibo_tweets(tweet_container_id=c_id,pages=1):\n",
        "            try:\n",
        "                check1 = 'created_at' in tweet['mblog']\n",
        "                check2 = 'attitudes_count' in tweet['mblog']\n",
        "                check3 = 'comments_count' in tweet['mblog']\n",
        "                check4 = 'reposts_count' in tweet['mblog']\n",
        "                check5 = 'text' in tweet['mblog']\n",
        "                \n",
        "                if check1 and check2 and check3 and check4 and check5:\n",
        "                    brand_name.append(brand)\n",
        "                    created_at.append(tweet['mblog']['created_at'])\n",
        "                    n_likes.append(tweet['mblog']['attitudes_count'])\n",
        "                    n_comments.append(tweet['mblog']['comments_count'])\n",
        "                    n_reposts.append(tweet['mblog']['reposts_count'])\n",
        "                    content.append(tweet['mblog']['text'])\n",
        "                    container_id.append(c_id)\n",
        "                    cnt = cnt+1\n",
        "\n",
        "                    if(cnt%100==0):\n",
        "                        print(f'processed {cnt} tweets')\n",
        "                        break\n",
        "\n",
        "            except:\n",
        "                print(\"tweet does not have attributes\")\n",
        "                continue\n",
        "    \n",
        "    df = pd.DataFrame(\n",
        "    {\n",
        "         'Brand': brand_name,\n",
        "         'Created_at': created_at,\n",
        "         'Likes': n_likes,\n",
        "         'Comments': n_comments,\n",
        "         'Reposts': n_reposts,\n",
        "         'Content': content,\n",
        "         'Container_ID': container_id\n",
        "    })\n",
        "    print(df)\n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "5c09380c",
      "metadata": {
        "id": "5c09380c",
        "outputId": "630cbb89-541b-4d17-ea99-6d524392f90e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8it [00:16,  2.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BMW has 80 number of posts\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 1/77 [00:01<01:19,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet does not have attributes\n",
            "tweet does not have attributes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/77 [00:02<01:21,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet does not have attributes\n",
            "tweet does not have attributes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 4/77 [00:04<01:25,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet does not have attributes\n",
            "tweet does not have attributes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 8/77 [00:10<01:33,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet does not have attributes\n",
            "tweet does not have attributes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 10/77 [00:13<01:29,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet does not have attributes\n",
            "tweet does not have attributes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 11/77 [00:14<01:27,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet does not have attributes\n",
            "tweet does not have attributes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 14/77 [00:18<01:26,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet does not have attributes\n",
            "tweet does not have attributes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 17/77 [00:23<01:21,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet does not have attributes\n",
            "tweet does not have attributes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 18/77 [00:24<01:14,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet does not have attributes\n",
            "tweet does not have attributes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 20/77 [00:26<01:12,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet does not have attributes\n",
            "tweet does not have attributes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 21/77 [00:27<01:07,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet does not have attributes\n",
            "tweet does not have attributes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 22/77 [00:28<01:03,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet does not have attributes\n",
            "tweet does not have attributes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 23/77 [00:29<01:00,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet does not have attributes\n",
            "tweet does not have attributes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 27/77 [00:36<01:09,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet does not have attributes\n",
            "tweet does not have attributes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 49/77 [01:09<00:44,  1.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet does not have attributes\n",
            "tweet does not have attributes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 51/77 [01:13<00:43,  1.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet does not have attributes\n",
            "tweet does not have attributes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 54/77 [01:17<00:34,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet does not have attributes\n",
            "tweet does not have attributes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 59/77 [01:24<00:23,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet does not have attributes\n",
            "tweet does not have attributes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 60/77 [01:25<00:21,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet does not have attributes\n",
            "tweet does not have attributes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 63/77 [01:29<00:19,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processed 100 tweets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [01:50<00:00,  1.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Brand                      Created_at  Likes  Comments  Reposts  \\\n",
            "0     BMW  Fri Mar 03 10:00:02 +0800 2023     87        18       19   \n",
            "1     BMW  Wed Mar 02 15:33:05 +0800 2022    111        14       36   \n",
            "2     BMW  Wed Jan 11 02:06:25 +0800 2023    163        55       74   \n",
            "3     BMW  Sat Jan 14 14:40:35 +0800 2023     23         6       15   \n",
            "4     BMW  Mon Feb 27 10:04:43 +0800 2023   1275        64      157   \n",
            "..    ...                             ...    ...       ...      ...   \n",
            "118   BMW  Sat Dec 31 21:38:31 +0800 2022  11148       475       28   \n",
            "119   BMW  Mon Dec 19 10:00:03 +0800 2022   7516       248      472   \n",
            "120   BMW  Mon Dec 19 10:10:02 +0800 2022     47         9       15   \n",
            "121   BMW  Mon Feb 20 11:20:03 +0800 2023   1031       139      604   \n",
            "122   BMW  Sun Feb 19 10:00:04 +0800 2023     69         7      190   \n",
            "\n",
            "                                               Content  \\\n",
            "0    <a  href=\"https://m.weibo.cn/search?containeri...   \n",
            "1    <a  href=\"https://m.weibo.cn/search?containeri...   \n",
            "2    稳、准、狠，让激情燃烧每一公里路。<span class=\"url-icon\"><img a...   \n",
            "3    月光族最后的倔强。雨天漫步，雨天遛车。<a  href=\"https://m.weibo.c...   \n",
            "4    <a  href=\"https://m.weibo.cn/search?containeri...   \n",
            "..                                                 ...   \n",
            "118  2023在健康平安的基础上，锦上添花吧<span class=\"url-icon\"><img...   \n",
            "119  还在等雪来？别等了！<a  href=\"https://m.weibo.cn/search?...   \n",
            "120  解锁冰封不羁灵魂，开启超燃雪季之旅。BMW ✖ ROSSIGNOL联名自由式雪板限量上市，上...   \n",
            "121  <a  href=\"https://m.weibo.cn/search?containeri...   \n",
            "122  大山如同一卷空白的画布，在粉雪上留下一道道漂亮的滑行轨迹 by silvertonmount...   \n",
            "\n",
            "                                          Container_ID  \n",
            "0    231522type%3D1%26t%3D10%26q%3D%23%E8%B6%85%E8%...  \n",
            "1    231522type%3D1%26t%3D10%26q%3D%23%E8%B6%85%E8%...  \n",
            "2           231522type%3D1%26t%3D10%26q%3D%23Bimmer%23  \n",
            "3           231522type%3D1%26t%3D10%26q%3D%23Bimmer%23  \n",
            "4    231522type%3D1%26t%3D10%26q%3D%23BMW%E7%83%AD%...  \n",
            "..                                                 ...  \n",
            "118  231522type%3D1%26t%3D10%26q%3D%23%E5%85%83%E6%...  \n",
            "119  231522type%3D1%26t%3D10%26q%3D%23%E7%83%AD%E9%...  \n",
            "120  231522type%3D1%26t%3D10%26q%3D%23%E7%83%AD%E9%...  \n",
            "121  231522type%3D1%26t%3D10%26q%3D%23%E7%83%AD%E9%...  \n",
            "122  231522type%3D1%26t%3D10%26q%3D%23%E7%83%AD%E9%...  \n",
            "\n",
            "[123 rows x 7 columns]\n",
            "Completed processing BMW data\n"
          ]
        }
      ],
      "source": [
        "accs = [\"BMW\"]\n",
        "for acc in accs:\n",
        "    posts = post_scraper(data_dict_en[acc])\n",
        "    containers = container_id_extractor(posts)\n",
        "    df = container_metadata_extractor(containers,acc)\n",
        "    df.to_excel(acc+\".xlsx\", index=False)\n",
        "    print(f\"Completed processing {acc} data\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gt7jO1jNd52N"
      },
      "id": "Gt7jO1jNd52N",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}